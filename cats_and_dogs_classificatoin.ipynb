{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_and_dogs_classificatoin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gowtham91m/cats-and-dogs-classification/blob/master/cats_and_dogs_classificatoin.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "iVLV8qY1LJNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import io, cv2, fnmatch, shutil, os, getpass, subprocess, random\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "from time import time\n",
        "from glob import glob\n",
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4Bpx7yjEvZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "if 'kaggle.txt' not in os.listdir('/content'):\n",
        "  from google.colab import files\n",
        "  downloaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84pSIWEYEvbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "c653b1ee-5729-4b69-d14d-b5a3081af8ac"
      },
      "cell_type": "code",
      "source": [
        "with open('kaggle.txt') as f: key = f.read()\n",
        "if 'cats_dogs' not in os.listdir('/content'):\n",
        "  os.mkdir('/content/cats_dogs')\n",
        "os.chdir('/content/cats_dogs')\n",
        "os.environ['KAGGLE_USERNAME']=\"gowham91m\"\n",
        "os.environ['KAGGLE_KEY']=key\n",
        "\n",
        "if 'cats_dogs' in os.listdir('/content'):shutil.rmtree('/content/cats_dogs')\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sampleSubmission.csv to /content/cats_dogs\n",
            "\r  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 22.1MB/s]\n",
            "Downloading test1.zip to /content/cats_dogs\n",
            " 94% 255M/271M [00:02<00:00, 96.4MB/s]\n",
            "100% 271M/271M [00:02<00:00, 111MB/s] \n",
            "Downloading train.zip to /content/cats_dogs\n",
            " 99% 537M/543M [00:04<00:00, 110MB/s]\n",
            "100% 543M/543M [00:04<00:00, 131MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3wrOx42FijD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ef66ac38-45bc-4a16-b142-3052d3aea65b"
      },
      "cell_type": "code",
      "source": [
        "!unzip -q -o train.zip\n",
        "!unzip -q -o test1.zip\n",
        "\n",
        "cat_pattern = '*cat.*.jpg'\n",
        "dog_pattern = '*dog.*.jpg'\n",
        "\n",
        "images = glob('/content/cats_dogs/train/*.jpg', recursive=True)\n",
        "cats = fnmatch.filter(images,cat_pattern)\n",
        "dogs = fnmatch.filter(images,dog_pattern)\n",
        "\n",
        "os.listdir('/content/cats_dogs')\n",
        "if 'data' not in os.listdir('/content/cats_dogs'):os.mkdir('/content/cats_dogs/data')\n",
        "if 'train' not in os.listdir('/content/cats_dogs/data'):os.mkdir('/content/cats_dogs/data/train')\n",
        "if 'dogs' not in os.listdir('/content/cats_dogs/data/train'):os.mkdir('/content/cats_dogs/data/train/dogs')\n",
        "if 'cats' not in os.listdir('/content/cats_dogs/data/train'):os.mkdir('/content/cats_dogs/data/train/cats')\n",
        "  \n",
        "if 'val' not in os.listdir('/content/cats_dogs/data'):os.mkdir('/content/cats_dogs/data/val')\n",
        "if 'dogs' not in os.listdir('/content/cats_dogs/data/val'):os.mkdir('/content/cats_dogs/data/val/dogs')\n",
        "if 'cats' not in os.listdir('/content/cats_dogs/data/val'):os.mkdir('/content/cats_dogs/data/val/cats')\n",
        "\n",
        "train_dogs_path = '/content/cats_dogs/data/train/dogs'\n",
        "train_cats_path = '/content/cats_dogs/data/train/cats'\n",
        "\n",
        "val_dogs_path = '/content/cats_dogs/data/val/dogs'\n",
        "val_cats_path = '/content/cats_dogs/data/val/cats'\n",
        "\n",
        "for file in cats: shutil.copy2(file, train_cats_path)\n",
        "for file in dogs: shutil.copy2(file, train_dogs_path)\n",
        "  \n",
        "  \n",
        "# split train date into train and validation\n",
        "train_len = len(os.listdir('/content/cats_dogs/data/train/dogs'))\n",
        "val_len = train_len * 0.3\n",
        "val_dogs = random.sample(os.listdir(train_dogs_path),int(val_len))\n",
        "val_cats = random.sample(os.listdir(train_cats_path),int(val_len))\n",
        "\n",
        "\n",
        "for file in val_dogs:\n",
        "  try: shutil.move(os.path.join(train_dogs_path,file), val_dogs_path)\n",
        "  except: pass\n",
        "for file in val_cats:\n",
        "  try: shutil.move(os.path.join(train_cats_path,file), val_cats_path)\n",
        "  except: pass\n",
        "  \n",
        "print(len(os.listdir(train_cats_path)))\n",
        "print(len(os.listdir(val_cats_path)))\n",
        "\n",
        "print(len(os.listdir(train_dogs_path)))\n",
        "print(len(os.listdir(val_dogs_path)))\n",
        "\n",
        "print('total train samples ', len(os.listdir(train_cats_path)) + len(os.listdir(train_dogs_path)))\n",
        "print('total train samples ', len(os.listdir(val_cats_path)) + len(os.listdir(val_dogs_path)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8750\n",
            "3750\n",
            "8750\n",
            "3750\n",
            "total train samples  17500\n",
            "total train samples  7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VRXlciBPMb7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6568031e-36fe-4ebd-d024-6194de41da1a"
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size=64\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/cats_dogs/data/train',  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary') \n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17500 images belonging to 2 classes.\n",
            "Found 7500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jfQhX7Y6MWR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "3241e40b-01eb-4e75-eec9-0819be452f23"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=( 150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time()\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        #steps_per_epoch=18631 // batch_size,\n",
        "        epochs=8,\n",
        "        validation_data=validation_generator,\n",
        "        #validation_steps=10119 // batch_size\n",
        "        )\n",
        "model.save_weights('first_try.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17500 images belonging to 2 classes.\n",
            "Found 7500 images belonging to 2 classes.\n",
            "Epoch 1/8\n",
            "274/274 [==============================] - 177s 647ms/step - loss: 0.6890 - acc: 0.5975 - val_loss: 0.6597 - val_acc: 0.6395\n",
            "Epoch 2/8\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 0.5706 - acc: 0.7096 - val_loss: 0.4954 - val_acc: 0.7588\n",
            "Epoch 3/8\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 0.5218 - acc: 0.7461 - val_loss: 0.4583 - val_acc: 0.7803\n",
            "Epoch 4/8\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 0.4866 - acc: 0.7696 - val_loss: 0.4228 - val_acc: 0.8003\n",
            "Epoch 5/8\n",
            "274/274 [==============================] - 171s 625ms/step - loss: 0.4651 - acc: 0.7865 - val_loss: 0.4928 - val_acc: 0.7748\n",
            "Epoch 6/8\n",
            "274/274 [==============================] - 172s 629ms/step - loss: 0.4427 - acc: 0.8000 - val_loss: 0.6010 - val_acc: 0.7573\n",
            "Epoch 7/8\n",
            "274/274 [==============================] - 172s 627ms/step - loss: 0.4286 - acc: 0.8091 - val_loss: 0.3932 - val_acc: 0.8160\n",
            "Epoch 8/8\n",
            "274/274 [==============================] - 171s 625ms/step - loss: 0.4121 - acc: 0.8159 - val_loss: 0.4204 - val_acc: 0.8077\n",
            "time taken  1376.3395261764526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "foaln3KF94Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "426cbccf-9669-4733-fea9-b5c16067f401"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "img_rows, img_cols, img_channel = 150, 150, 3\n",
        "base_model = VGG16(weights='imagenet'\n",
        "                   ,include_top=False, input_shape=(img_rows, img_cols, img_channel), classes = 2)\n",
        "\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(128, activation='relu'))\n",
        "add_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "vgg_model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "    \n",
        "vgg_model.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "start_time = time()\n",
        "vgg_model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=16,\n",
        "        validation_data=validation_generator,\n",
        "        #class_weight = class_weights,\n",
        "        callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)])\n",
        "vgg_model.save_weights('vgg16.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "274/274 [==============================] - 205s 747ms/step - loss: 0.5454 - acc: 0.7449 - val_loss: 0.4328 - val_acc: 0.8332\n",
            "Epoch 2/16\n",
            "274/274 [==============================] - 199s 727ms/step - loss: 0.4224 - acc: 0.8273 - val_loss: 0.3719 - val_acc: 0.8545\n",
            "Epoch 3/16\n",
            "274/274 [==============================] - 197s 721ms/step - loss: 0.3802 - acc: 0.8424 - val_loss: 0.3454 - val_acc: 0.8624\n",
            "Epoch 4/16\n",
            "274/274 [==============================] - 197s 719ms/step - loss: 0.3544 - acc: 0.8529 - val_loss: 0.3254 - val_acc: 0.8687\n",
            "Epoch 5/16\n",
            "274/274 [==============================] - 198s 722ms/step - loss: 0.3405 - acc: 0.8587 - val_loss: 0.3121 - val_acc: 0.8743\n",
            "Epoch 6/16\n",
            "274/274 [==============================] - 196s 717ms/step - loss: 0.3294 - acc: 0.8621 - val_loss: 0.3042 - val_acc: 0.8744\n",
            "Epoch 7/16\n",
            "274/274 [==============================] - 199s 725ms/step - loss: 0.3179 - acc: 0.8685 - val_loss: 0.2938 - val_acc: 0.8788\n",
            "Epoch 8/16\n",
            "274/274 [==============================] - 200s 731ms/step - loss: 0.3086 - acc: 0.8716 - val_loss: 0.2870 - val_acc: 0.8828\n",
            "Epoch 9/16\n",
            "274/274 [==============================] - 201s 732ms/step - loss: 0.3007 - acc: 0.8737 - val_loss: 0.2821 - val_acc: 0.8827\n",
            "Epoch 10/16\n",
            "274/274 [==============================] - 255s 930ms/step - loss: 0.2955 - acc: 0.8770 - val_loss: 0.2785 - val_acc: 0.8835\n",
            "Epoch 11/16\n",
            "274/274 [==============================] - 219s 800ms/step - loss: 0.2873 - acc: 0.8796 - val_loss: 0.2719 - val_acc: 0.8880\n",
            "Epoch 12/16\n",
            "274/274 [==============================] - 200s 729ms/step - loss: 0.2852 - acc: 0.8807 - val_loss: 0.2704 - val_acc: 0.8873\n",
            "Epoch 13/16\n",
            "274/274 [==============================] - 198s 723ms/step - loss: 0.2823 - acc: 0.8803 - val_loss: 0.2647 - val_acc: 0.8925\n",
            "Epoch 14/16\n",
            "274/274 [==============================] - 200s 729ms/step - loss: 0.2776 - acc: 0.8856 - val_loss: 0.2617 - val_acc: 0.8937\n",
            "Epoch 15/16\n",
            "274/274 [==============================] - 201s 733ms/step - loss: 0.2737 - acc: 0.8860 - val_loss: 0.2709 - val_acc: 0.8869\n",
            "Epoch 16/16\n",
            "274/274 [==============================] - 200s 728ms/step - loss: 0.2721 - acc: 0.8857 - val_loss: 0.2574 - val_acc: 0.8931\n",
            "time taken  3267.4616470336914\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}