{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_and_dogs_classificatoin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gowtham91m/cats-and-dogs-classification/blob/master/cats_and_dogs_classificatoin.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "iVLV8qY1LJNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import io, cv2, fnmatch, shutil, os, getpass, subprocess, random\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "from time import time\n",
        "from glob import glob\n",
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4Bpx7yjEvZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "if 'cats_dogs' in os.listdir('/content'):shutil.rmtree('/content/cats_dogs')\n",
        "if 'kaggle.txt' not in os.listdir('/content'):\n",
        "  from google.colab import files\n",
        "  downloaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84pSIWEYEvbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "74a7e03b-9d03-41cd-f2e4-0f61ac515105"
      },
      "cell_type": "code",
      "source": [
        "with open('kaggle.txt') as f: key = f.read()\n",
        "if 'cats_dogs' not in os.listdir('/content'):\n",
        "  os.mkdir('/content/cats_dogs')\n",
        "os.chdir('/content/cats_dogs')\n",
        "os.environ['KAGGLE_USERNAME']=\"gowham91m\"\n",
        "os.environ['KAGGLE_KEY']=key\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sampleSubmission.csv to /content/cats_dogs\n",
            "\r  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 36.5MB/s]\n",
            "Downloading test1.zip to /content/cats_dogs\n",
            " 98% 265M/271M [00:04<00:00, 74.9MB/s]\n",
            "100% 271M/271M [00:04<00:00, 67.5MB/s]\n",
            "Downloading train.zip to /content/cats_dogs\n",
            " 99% 538M/543M [00:03<00:00, 133MB/s]\n",
            "100% 543M/543M [00:03<00:00, 176MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3wrOx42FijD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4a2c095e-98c1-49d6-c3c0-2ae2526aa439"
      },
      "cell_type": "code",
      "source": [
        "!unzip -q -o train.zip\n",
        "!unzip -q -o test1.zip\n",
        "\n",
        "cat_pattern = '*cat.*.jpg'\n",
        "dog_pattern = '*dog.*.jpg'\n",
        "\n",
        "images = glob('/content/cats_dogs/train/*.jpg', recursive=True)\n",
        "cats = fnmatch.filter(images,cat_pattern)\n",
        "dogs = fnmatch.filter(images,dog_pattern)\n",
        "\n",
        "os.listdir('/content/cats_dogs')\n",
        "if 'data' not in os.listdir('/content/cats_dogs'):os.mkdir('/content/cats_dogs/data')\n",
        "if 'train' not in os.listdir('/content/cats_dogs/data'):os.mkdir('/content/cats_dogs/data/train')\n",
        "if 'dogs' not in os.listdir('/content/cats_dogs/data/train'):os.mkdir('/content/cats_dogs/data/train/dogs')\n",
        "if 'cats' not in os.listdir('/content/cats_dogs/data/train'):os.mkdir('/content/cats_dogs/data/train/cats')\n",
        "  \n",
        "if 'val' not in os.listdir('/content/cats_dogs/data'):os.mkdir('/content/cats_dogs/data/val')\n",
        "if 'dogs' not in os.listdir('/content/cats_dogs/data/val'):os.mkdir('/content/cats_dogs/data/val/dogs')\n",
        "if 'cats' not in os.listdir('/content/cats_dogs/data/val'):os.mkdir('/content/cats_dogs/data/val/cats')\n",
        "\n",
        "train_dogs_path = '/content/cats_dogs/data/train/dogs'\n",
        "train_cats_path = '/content/cats_dogs/data/train/cats'\n",
        "\n",
        "val_dogs_path = '/content/cats_dogs/data/val/dogs'\n",
        "val_cats_path = '/content/cats_dogs/data/val/cats'\n",
        "\n",
        "for file in cats: shutil.copy2(file, train_cats_path)\n",
        "for file in dogs: shutil.copy2(file, train_dogs_path)\n",
        "  \n",
        "  \n",
        "# split train date into train and validation\n",
        "train_len = len(os.listdir('/content/cats_dogs/data/train/dogs'))\n",
        "val_len = train_len * 0.3\n",
        "val_dogs = random.sample(os.listdir(train_dogs_path),int(val_len))\n",
        "val_cats = random.sample(os.listdir(train_cats_path),int(val_len))\n",
        "\n",
        "\n",
        "for file in val_dogs:\n",
        "  try: shutil.move(os.path.join(train_dogs_path,file), val_dogs_path)\n",
        "  except: pass\n",
        "for file in val_cats:\n",
        "  try: shutil.move(os.path.join(train_cats_path,file), val_cats_path)\n",
        "  except: pass\n",
        "  \n",
        "  \n",
        "  \n",
        "print(len(os.listdir(train_cats_path)))\n",
        "print(len(os.listdir(val_cats_path)))\n",
        "\n",
        "print(len(os.listdir(train_dogs_path)))\n",
        "print(len(os.listdir(val_dogs_path)))\n",
        "\n",
        "print('total train samples ', len(os.listdir(train_cats_path)) + len(os.listdir(train_dogs_path)))\n",
        "print('total train samples ', len(os.listdir(val_cats_path)) + len(os.listdir(val_dogs_path)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8750\n",
            "3750\n",
            "8750\n",
            "3750\n",
            "total train samples  17500\n",
            "total train samples  7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RmjSxgO0QtmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VRXlciBPMb7P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size=64\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/cats_dogs/data/train',  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary') \n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfQhX7Y6MWR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "3241e40b-01eb-4e75-eec9-0819be452f23"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=( 150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "start_time = time()\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        #steps_per_epoch=18631 // batch_size,\n",
        "        epochs=8,\n",
        "        validation_data=validation_generator,\n",
        "        #validation_steps=10119 // batch_size\n",
        "        )\n",
        "model.save_weights('first_try.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17500 images belonging to 2 classes.\n",
            "Found 7500 images belonging to 2 classes.\n",
            "Epoch 1/8\n",
            "274/274 [==============================] - 177s 647ms/step - loss: 0.6890 - acc: 0.5975 - val_loss: 0.6597 - val_acc: 0.6395\n",
            "Epoch 2/8\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 0.5706 - acc: 0.7096 - val_loss: 0.4954 - val_acc: 0.7588\n",
            "Epoch 3/8\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 0.5218 - acc: 0.7461 - val_loss: 0.4583 - val_acc: 0.7803\n",
            "Epoch 4/8\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 0.4866 - acc: 0.7696 - val_loss: 0.4228 - val_acc: 0.8003\n",
            "Epoch 5/8\n",
            "274/274 [==============================] - 171s 625ms/step - loss: 0.4651 - acc: 0.7865 - val_loss: 0.4928 - val_acc: 0.7748\n",
            "Epoch 6/8\n",
            "274/274 [==============================] - 172s 629ms/step - loss: 0.4427 - acc: 0.8000 - val_loss: 0.6010 - val_acc: 0.7573\n",
            "Epoch 7/8\n",
            "274/274 [==============================] - 172s 627ms/step - loss: 0.4286 - acc: 0.8091 - val_loss: 0.3932 - val_acc: 0.8160\n",
            "Epoch 8/8\n",
            "274/274 [==============================] - 171s 625ms/step - loss: 0.4121 - acc: 0.8159 - val_loss: 0.4204 - val_acc: 0.8077\n",
            "time taken  1376.3395261764526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "foaln3KF94Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "284bd946-96e1-4266-ca54-51e524927a04"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "img_rows, img_cols, img_channel = 150, 150, 3\n",
        "base_model = VGG16(weights='imagenet'\n",
        "                   ,include_top=False, input_shape=(img_rows, img_cols, img_channel), classes = 2)\n",
        "\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(128, activation='relu'))\n",
        "add_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "vgg_model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "    \n",
        "vgg_model.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "start_time = time()\n",
        "vgg_model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=8,\n",
        "        validation_data=validation_generator,\n",
        "        #class_weight = class_weights,\n",
        "        callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)])\n",
        "vgg_model.save_weights('vgg16.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "274/274 [==============================] - 208s 758ms/step - loss: 0.5588 - acc: 0.7308 - val_loss: 0.4477 - val_acc: 0.8191\n",
            "Epoch 2/8\n",
            "274/274 [==============================] - 201s 733ms/step - loss: 0.4333 - acc: 0.8184 - val_loss: 0.3863 - val_acc: 0.8401\n",
            "Epoch 3/8\n",
            "274/274 [==============================] - 200s 730ms/step - loss: 0.3848 - acc: 0.8429 - val_loss: 0.3497 - val_acc: 0.8571\n",
            "Epoch 4/8\n",
            "274/274 [==============================] - 199s 727ms/step - loss: 0.3606 - acc: 0.8492 - val_loss: 0.3287 - val_acc: 0.8655\n",
            "Epoch 5/8\n",
            "274/274 [==============================] - 198s 724ms/step - loss: 0.3408 - acc: 0.8563 - val_loss: 0.3138 - val_acc: 0.8704\n",
            "Epoch 6/8\n",
            "274/274 [==============================] - 199s 725ms/step - loss: 0.3288 - acc: 0.8605 - val_loss: 0.3022 - val_acc: 0.8767\n",
            "Epoch 7/8\n",
            "274/274 [==============================] - 202s 738ms/step - loss: 0.3171 - acc: 0.8699 - val_loss: 0.2928 - val_acc: 0.8795\n",
            "Epoch 8/8\n",
            "274/274 [==============================] - 203s 742ms/step - loss: 0.3079 - acc: 0.8716 - val_loss: 0.2858 - val_acc: 0.8832\n",
            "time taken  1612.191948890686\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}