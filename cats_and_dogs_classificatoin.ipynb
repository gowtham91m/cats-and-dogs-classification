{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_and_dogs_classificatoin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "V9zA0ChBu75g"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gowtham91m/cats-and-dogs-classification/blob/master/cats_and_dogs_classificatoin.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "iVLV8qY1LJNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import io, cv2, fnmatch, shutil, os, getpass, subprocess, random\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "from time import time\n",
        "from glob import glob\n",
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4Bpx7yjEvZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "if 'kaggle.txt' not in os.listdir('/content'):\n",
        "  from google.colab import files\n",
        "  downloaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4K9_ZZtVXjdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "5f159832-94f3-4aee-c310-7fe9169d0c21"
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "with open('kaggle.txt') as f: key = f.read()\n",
        "os.environ['KAGGLE_USERNAME']=\"gowham91m\"\n",
        "os.environ['KAGGLE_KEY']=key\n",
        "if 'cats_dogs' in os.listdir('/content'):shutil.rmtree('/content/cats_dogs')\n",
        "os.mkdir('/content/cats_dogs')\n",
        "os.chdir('/content/cats_dogs')\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sampleSubmission.csv to /content/cats_dogs\n",
            "\r  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 39.7MB/s]\n",
            "Downloading test1.zip to /content/cats_dogs\n",
            " 99% 268M/271M [00:01<00:00, 121MB/s]\n",
            "100% 271M/271M [00:01<00:00, 144MB/s]\n",
            "Downloading train.zip to /content/cats_dogs\n",
            " 98% 533M/543M [00:04<00:00, 128MB/s]\n",
            "100% 543M/543M [00:04<00:00, 124MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3wrOx42FijD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ae222f9e-2d1e-4bb5-91ec-a9473d75bd3c"
      },
      "cell_type": "code",
      "source": [
        "!unzip -q -o train.zip\n",
        "!unzip -q -o test1.zip\n",
        "\n",
        "cat_pattern = '*cat.*.jpg'\n",
        "dog_pattern = '*dog.*.jpg'\n",
        "\n",
        "images = glob('/content/cats_dogs/train/*.jpg', recursive=True)\n",
        "cats = fnmatch.filter(images,cat_pattern)\n",
        "dogs = fnmatch.filter(images,dog_pattern)\n",
        "\n",
        "os.listdir('/content/cats_dogs')\n",
        "if 'data' not in os.listdir('/content/cats_dogs'):os.mkdir('/content/cats_dogs/data')\n",
        "if 'train' not in os.listdir('/content/cats_dogs/data'):os.mkdir('/content/cats_dogs/data/train')\n",
        "if 'dogs' not in os.listdir('/content/cats_dogs/data/train'):os.mkdir('/content/cats_dogs/data/train/dogs')\n",
        "if 'cats' not in os.listdir('/content/cats_dogs/data/train'):os.mkdir('/content/cats_dogs/data/train/cats')\n",
        "  \n",
        "if 'val' not in os.listdir('/content/cats_dogs/data'):os.mkdir('/content/cats_dogs/data/val')\n",
        "if 'dogs' not in os.listdir('/content/cats_dogs/data/val'):os.mkdir('/content/cats_dogs/data/val/dogs')\n",
        "if 'cats' not in os.listdir('/content/cats_dogs/data/val'):os.mkdir('/content/cats_dogs/data/val/cats')\n",
        "\n",
        "train_dogs_path = '/content/cats_dogs/data/train/dogs'\n",
        "train_cats_path = '/content/cats_dogs/data/train/cats'\n",
        "\n",
        "val_dogs_path = '/content/cats_dogs/data/val/dogs'\n",
        "val_cats_path = '/content/cats_dogs/data/val/cats'\n",
        "\n",
        "for file in cats: shutil.copy2(file, train_cats_path)\n",
        "for file in dogs: shutil.copy2(file, train_dogs_path)\n",
        "  \n",
        "  \n",
        "# split train date into train and validation\n",
        "train_len = len(os.listdir('/content/cats_dogs/data/train/dogs'))\n",
        "val_len = train_len * 0.3\n",
        "val_dogs = random.sample(os.listdir(train_dogs_path),int(val_len))\n",
        "val_cats = random.sample(os.listdir(train_cats_path),int(val_len))\n",
        "\n",
        "\n",
        "for file in val_dogs:\n",
        "  try: shutil.move(os.path.join(train_dogs_path,file), val_dogs_path)\n",
        "  except: pass\n",
        "for file in val_cats:\n",
        "  try: shutil.move(os.path.join(train_cats_path,file), val_cats_path)\n",
        "  except: pass\n",
        "  \n",
        "print(len(os.listdir(train_cats_path)))\n",
        "print(len(os.listdir(val_cats_path)))\n",
        "\n",
        "print(len(os.listdir(train_dogs_path)))\n",
        "print(len(os.listdir(val_dogs_path)))\n",
        "\n",
        "print('total train samples ', len(os.listdir(train_cats_path)) + len(os.listdir(train_dogs_path)))\n",
        "print('total train samples ', len(os.listdir(val_cats_path)) + len(os.listdir(val_dogs_path)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8750\n",
            "3750\n",
            "8750\n",
            "3750\n",
            "total train samples  17500\n",
            "total train samples  7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VRXlciBPMb7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "015fa3d6-2bbc-4be9-de01-0b218902a064"
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size=64\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/cats_dogs/data/train',  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary') \n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17500 images belonging to 2 classes.\n",
            "Found 7500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zPtRx1P_vCBF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#CNN classifier"
      ]
    },
    {
      "metadata": {
        "id": "M8bbF3egoK2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "bfc95991-8f55-4a53-d9d1-15ae48d16b84"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=( 150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time()\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        #steps_per_epoch=18631 // batch_size,\n",
        "        epochs=8,\n",
        "        validation_data=validation_generator,\n",
        "        #validation_steps=10119 // batch_size\n",
        "        )\n",
        "model.save_weights('first_try.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "274/274 [==============================] - 172s 627ms/step - loss: 0.6679 - acc: 0.5996 - val_loss: 0.5909 - val_acc: 0.6855\n",
            "Epoch 2/8\n",
            "274/274 [==============================] - 166s 604ms/step - loss: 0.5696 - acc: 0.7036 - val_loss: 0.6113 - val_acc: 0.6675\n",
            "Epoch 3/8\n",
            "274/274 [==============================] - 164s 599ms/step - loss: 0.5059 - acc: 0.7511 - val_loss: 0.4475 - val_acc: 0.7900\n",
            "Epoch 4/8\n",
            "274/274 [==============================] - 164s 599ms/step - loss: 0.4495 - acc: 0.7910 - val_loss: 0.3938 - val_acc: 0.8221\n",
            "Epoch 5/8\n",
            "274/274 [==============================] - 163s 594ms/step - loss: 0.4114 - acc: 0.8134 - val_loss: 0.3711 - val_acc: 0.8357\n",
            "Epoch 6/8\n",
            "274/274 [==============================] - 166s 607ms/step - loss: 0.3761 - acc: 0.8308 - val_loss: 0.3217 - val_acc: 0.8556\n",
            "Epoch 7/8\n",
            "274/274 [==============================] - 165s 602ms/step - loss: 0.3484 - acc: 0.8474 - val_loss: 0.3154 - val_acc: 0.8676\n",
            "Epoch 8/8\n",
            "274/274 [==============================] - 165s 603ms/step - loss: 0.3266 - acc: 0.8570 - val_loss: 0.3376 - val_acc: 0.8520\n",
            "time taken  1325.7359902858734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V9zA0ChBu75g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#VGG16 transfer learning"
      ]
    },
    {
      "metadata": {
        "id": "foaln3KF94Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "426cbccf-9669-4733-fea9-b5c16067f401"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "img_rows, img_cols, img_channel = 150, 150, 3\n",
        "base_model = VGG16(weights='imagenet'\n",
        "                   ,include_top=False, input_shape=(img_rows, img_cols, img_channel), classes = 2)\n",
        "\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(128, activation='relu'))\n",
        "add_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "vgg_model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "    \n",
        "vgg_model.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "start_time = time()\n",
        "vgg_model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=16,\n",
        "        validation_data=validation_generator,\n",
        "        #class_weight = class_weights,\n",
        "        callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)])\n",
        "vgg_model.save_weights('vgg16.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "274/274 [==============================] - 205s 747ms/step - loss: 0.5454 - acc: 0.7449 - val_loss: 0.4328 - val_acc: 0.8332\n",
            "Epoch 2/16\n",
            "274/274 [==============================] - 199s 727ms/step - loss: 0.4224 - acc: 0.8273 - val_loss: 0.3719 - val_acc: 0.8545\n",
            "Epoch 3/16\n",
            "274/274 [==============================] - 197s 721ms/step - loss: 0.3802 - acc: 0.8424 - val_loss: 0.3454 - val_acc: 0.8624\n",
            "Epoch 4/16\n",
            "274/274 [==============================] - 197s 719ms/step - loss: 0.3544 - acc: 0.8529 - val_loss: 0.3254 - val_acc: 0.8687\n",
            "Epoch 5/16\n",
            "274/274 [==============================] - 198s 722ms/step - loss: 0.3405 - acc: 0.8587 - val_loss: 0.3121 - val_acc: 0.8743\n",
            "Epoch 6/16\n",
            "274/274 [==============================] - 196s 717ms/step - loss: 0.3294 - acc: 0.8621 - val_loss: 0.3042 - val_acc: 0.8744\n",
            "Epoch 7/16\n",
            "274/274 [==============================] - 199s 725ms/step - loss: 0.3179 - acc: 0.8685 - val_loss: 0.2938 - val_acc: 0.8788\n",
            "Epoch 8/16\n",
            "274/274 [==============================] - 200s 731ms/step - loss: 0.3086 - acc: 0.8716 - val_loss: 0.2870 - val_acc: 0.8828\n",
            "Epoch 9/16\n",
            "274/274 [==============================] - 201s 732ms/step - loss: 0.3007 - acc: 0.8737 - val_loss: 0.2821 - val_acc: 0.8827\n",
            "Epoch 10/16\n",
            "274/274 [==============================] - 255s 930ms/step - loss: 0.2955 - acc: 0.8770 - val_loss: 0.2785 - val_acc: 0.8835\n",
            "Epoch 11/16\n",
            "274/274 [==============================] - 219s 800ms/step - loss: 0.2873 - acc: 0.8796 - val_loss: 0.2719 - val_acc: 0.8880\n",
            "Epoch 12/16\n",
            "274/274 [==============================] - 200s 729ms/step - loss: 0.2852 - acc: 0.8807 - val_loss: 0.2704 - val_acc: 0.8873\n",
            "Epoch 13/16\n",
            "274/274 [==============================] - 198s 723ms/step - loss: 0.2823 - acc: 0.8803 - val_loss: 0.2647 - val_acc: 0.8925\n",
            "Epoch 14/16\n",
            "274/274 [==============================] - 200s 729ms/step - loss: 0.2776 - acc: 0.8856 - val_loss: 0.2617 - val_acc: 0.8937\n",
            "Epoch 15/16\n",
            "274/274 [==============================] - 201s 733ms/step - loss: 0.2737 - acc: 0.8860 - val_loss: 0.2709 - val_acc: 0.8869\n",
            "Epoch 16/16\n",
            "274/274 [==============================] - 200s 728ms/step - loss: 0.2721 - acc: 0.8857 - val_loss: 0.2574 - val_acc: 0.8931\n",
            "time taken  3267.4616470336914\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}